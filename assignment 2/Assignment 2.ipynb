{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19aa6d28-52f1-40fa-8a33-3e4504bf465d",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "Solution by Wiktor Dobrosierdow (Group 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fd2ed5-609e-4081-941c-e60ecaaedba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb65a2d-760a-4b85-9be9-fc63c909c44c",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "First task is the A-Priori algorithm. There are several supporting functions described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d1fea-e5c5-453c-a726-6ce185068cfd",
   "metadata": {},
   "source": [
    "### Generating candidate itemsets\n",
    "This function will generate candidate $k$-itemsets from the provided pool of *itemsets*.\n",
    "The two outer loops will process pairs of subsets from *itemsets*, generating a potential candidate.\n",
    "The candidate is then checked for validity according to the algorithm rules, and finally added to the list of suitable candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bff323f-0624-4124-881c-5a11c4dbe671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_itemsets(itemsets, k):\n",
    "    candidates = set()\n",
    "    itemsets = list(itemsets)\n",
    "    for i, A in enumerate(itemsets):\n",
    "        for B in itemsets[i + 1:]:\n",
    "            candidate = A | B\n",
    "            if not (len(candidate) == k and len(A & B) == k - 2):\n",
    "                continue\n",
    "            subsets = map(lambda item: candidate - frozenset((item,)), candidate)\n",
    "            if not all(subset in itemsets for subset in subsets):\n",
    "                continue\n",
    "            candidates.add(candidate)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7896592-6dc1-4c37-a4e0-b562e966aa30",
   "metadata": {},
   "source": [
    "### Pruning\n",
    "Rather simple, this function filters out itemsets which are below the support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3555f9-bb03-45bd-87f1-7ac201efe3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(freq_itemsets, threshold):\n",
    "    return {itemset:support for itemset, support in freq_itemsets.items() if support >= threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775eb22b-1ff2-4a4d-a983-802decf91c2f",
   "metadata": {},
   "source": [
    "### Counting singletons\n",
    "This function starts the A-Priori algorithm by counting the number of $1$-itemsets (singletons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c245bc1-35e2-4bb6-a1d0-c5f56ed2f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_singletons(dataset, threshold):\n",
    "    freq_items = defaultdict(int)\n",
    "    for row in dataset:\n",
    "        for item in row:\n",
    "            freq_items[item] += 1\n",
    "\n",
    "    return {frozenset((item,)):support for item, support in freq_items.items() if support >= threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6debea7-7bb3-42d1-8460-618c89aa2d61",
   "metadata": {},
   "source": [
    "### Candidates' support\n",
    "This function is used in the main loop to count the support of the generated candidate itemsets.\n",
    "There is an optimization for $k < 3$ (i.e. $k = 2$), where the number of candidates can be very large, and it is more efficient to simply generate all possible combinations of length $k = 2$ for each row, and check whether those combinations are a candidate.\n",
    "This optimization only works for low $k$, as larger values result in exponentially more combinations.\n",
    "It does provide a very sizeable peformance improvement for the first pass of $k = 2$ however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139faf2d-a59b-4b09-8991-18861b4c415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_count(dataset, candidates, k):\n",
    "    freq_itemsets = defaultdict(int)\n",
    "    if k < 3:\n",
    "        for row in dataset:\n",
    "            for subset in map(frozenset, combinations(row, k)):\n",
    "                if subset in candidates:\n",
    "                    freq_itemsets[subset] += 1\n",
    "    else:\n",
    "        for row in dataset:\n",
    "            for candidate in candidates:\n",
    "                if candidate.issubset(row):\n",
    "                    freq_itemsets[candidate] += 1\n",
    "    return freq_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f462b-cf82-4cbd-a2e9-cfa3408786a4",
   "metadata": {},
   "source": [
    "### Multiprocessing support\n",
    "Splitting the support counting calculation over several cores provides a good boost to performance. It would make sense to only use this when number of candidates is large, but it does not result in too much overhead even with a low number of candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cdfa6a-5721-4a33-8e80-edab0dc31b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(args):\n",
    "    return support_count(*args)\n",
    "\n",
    "def support_count_mp(dataset, candidates, k):\n",
    "    numproc = cpu_count()\n",
    "    chunk_size = len(dataset) // numproc\n",
    "    chunks = [dataset[i:i + chunk_size] for i in range(0, len(dataset), chunk_size)]\n",
    "    args = [(chunk, candidates, k) for chunk in chunks]\n",
    "\n",
    "    with Pool(numproc) as pool:\n",
    "        results = pool.map(worker, args)\n",
    "\n",
    "    total_freq_itemsets = defaultdict(int)\n",
    "    for result in results:\n",
    "        for itemset, support in result.items():\n",
    "            total_freq_itemsets[itemset] += support\n",
    "\n",
    "    return total_freq_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde279c0-1ae4-47f3-b150-98c18707f470",
   "metadata": {},
   "source": [
    "### A-Priori\n",
    "The star of the show, the `apriori` function. It combines the previously defined helper functions to run the actual algorithm. The frequent itemsets are initialized from the $1$-itemsets, and then progressively extended after testing larger and larget values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106b6fa1-e8c6-41a2-8d28-37dffe82085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataset, threshold):\n",
    "    freq_itemsets = freq_singletons(dataset, threshold)\n",
    "\n",
    "    last_freq_itemsets = freq_itemsets.copy()\n",
    "\n",
    "    k = 2\n",
    "    print(len(dataset))\n",
    "    while last_freq_itemsets:\n",
    "        candidates = generate_candidate_itemsets(last_freq_itemsets, k)\n",
    "        print(f'k = {k}, candidates ({len(candidates)})')\n",
    "\n",
    "        if not candidates:\n",
    "            break\n",
    "\n",
    "        t1 = time.time()\n",
    "        tmp_freq_itemsets = support_count_mp(dataset, candidates, k)\n",
    "        print(f'tmp_freq took {time.time() - t1} seconds')\n",
    "\n",
    "        last_freq_itemsets = prune(tmp_freq_itemsets, threshold)\n",
    "        freq_itemsets.update(last_freq_itemsets)\n",
    "        k += 1\n",
    "    print(f'final k: {k}')\n",
    "\n",
    "    return freq_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552c993-608d-4448-bae4-5509d5793a75",
   "metadata": {},
   "source": [
    "### Dataset loading\n",
    "The dataset is a list of transactions separated by newlines. Each transaction is a list of product IDs separated by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00979097-865a-40a0-902e-09e9b721ac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 100000\n",
      "CPU times: user 221 ms, sys: 55.5 ms, total: 276 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_dataset(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        dataset = [set(map(int, line.split())) for line in fp.read().splitlines()]\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset('T10I4D100K.dat')\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "if 0:\n",
    "    print('Dataset sample:')\n",
    "    for row in dataset[:5]:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7bcff2-0f20-4032-be31-4d7f0027e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "k = 2, candidates (161596)\n",
      "tmp_freq took 3.6372265815734863 seconds\n",
      "k = 3, candidates (170)\n",
      "tmp_freq took 1.2574200630187988 seconds\n",
      "k = 4, candidates (43)\n",
      "tmp_freq took 0.28475117683410645 seconds\n",
      "k = 5, candidates (10)\n",
      "tmp_freq took 0.2430574893951416 seconds\n",
      "k = 6, candidates (1)\n",
      "tmp_freq took 0.22603464126586914 seconds\n",
      "final k: 7\n",
      "CPU times: user 5.19 s, sys: 1.28 s, total: 6.47 s\n",
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "support_threshold = 500\n",
    "freq_itemsets = apriori(dataset, support_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c18b4c-2dd5-41eb-a59a-7322ce364a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets and their Support:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemset</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(368)</td>\n",
       "      <td>7828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>(529)</td>\n",
       "      <td>7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>(829)</td>\n",
       "      <td>6810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(766)</td>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(722)</td>\n",
       "      <td>5845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>(75, 325)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>(569, 461)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>(120, 638)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>(192, 935, 487)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>(105, 494, 862, 815)</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1073 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Itemset  Support\n",
       "7                    (368)     7828\n",
       "62                   (529)     7057\n",
       "223                  (829)     6810\n",
       "49                   (766)     6265\n",
       "164                  (722)     5845\n",
       "...                    ...      ...\n",
       "799              (75, 325)      500\n",
       "598             (569, 461)      500\n",
       "791             (120, 638)      500\n",
       "948        (192, 935, 487)      500\n",
       "1053  (105, 494, 862, 815)      500\n",
       "\n",
       "[1073 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = pd.DataFrame([\n",
    "    {'Itemset': itemset, 'Support': support}\n",
    "    for itemset, support in freq_itemsets.items()\n",
    "]).sort_values('Support', ascending=False)\n",
    "frame2 = pd.DataFrame([\n",
    "    {'support': int(support), 'itemsets': itemsets}\n",
    "    for itemsets, support in freq_itemsets.items()\n",
    "])\n",
    "#del freq_itemsets\n",
    "\n",
    "print('Frequent Itemsets and their Support:')\n",
    "display(frame)\n",
    "del frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed545bdb-dbcb-4431-afed-ef01b681810a",
   "metadata": {},
   "source": [
    "## Bonus Task\n",
    "The task is to use the frequent itemsets generated from the A-Priori algorithm to generate association rules between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1616aae9-fcbe-4e1a-96d7-33c444d02893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antecedent</th>\n",
       "      <th>Consequent</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(626)</td>\n",
       "      <td>(496)</td>\n",
       "      <td>761</td>\n",
       "      <td>0.870709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(801)</td>\n",
       "      <td>(392)</td>\n",
       "      <td>664</td>\n",
       "      <td>0.795210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(801)</td>\n",
       "      <td>(862)</td>\n",
       "      <td>674</td>\n",
       "      <td>0.807186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(842)</td>\n",
       "      <td>(579)</td>\n",
       "      <td>600</td>\n",
       "      <td>0.797872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(842)</td>\n",
       "      <td>(803)</td>\n",
       "      <td>607</td>\n",
       "      <td>0.807181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>(217, 546, 947, 661)</td>\n",
       "      <td>(923)</td>\n",
       "      <td>559</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>(546, 947, 923, 661)</td>\n",
       "      <td>(217)</td>\n",
       "      <td>559</td>\n",
       "      <td>0.967128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>(217, 546, 947, 923)</td>\n",
       "      <td>(661)</td>\n",
       "      <td>559</td>\n",
       "      <td>0.991135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>(217, 546, 923, 661)</td>\n",
       "      <td>(947)</td>\n",
       "      <td>559</td>\n",
       "      <td>0.978984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>(217, 947, 923, 661)</td>\n",
       "      <td>(546)</td>\n",
       "      <td>559</td>\n",
       "      <td>0.984155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Antecedent Consequent  Support  Confidence\n",
       "0                   (626)      (496)      761    0.870709\n",
       "1                   (801)      (392)      664    0.795210\n",
       "2                   (801)      (862)      674    0.807186\n",
       "3                   (842)      (579)      600    0.797872\n",
       "4                   (842)      (803)      607    0.807181\n",
       "..                    ...        ...      ...         ...\n",
       "959  (217, 546, 947, 661)      (923)      559    0.977273\n",
       "960  (546, 947, 923, 661)      (217)      559    0.967128\n",
       "961  (217, 546, 947, 923)      (661)      559    0.991135\n",
       "962  (217, 546, 923, 661)      (947)      559    0.978984\n",
       "963  (217, 947, 923, 661)      (546)      559    0.984155\n",
       "\n",
       "[964 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_association_rules(freq_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset, support in freq_itemsets.items():\n",
    "        if len(itemset) < 2:\n",
    "            # cannot generate any rules from 1-itemsets\n",
    "            continue\n",
    "\n",
    "        # generate all possible non-empty proper subsets of the itemset\n",
    "        subsets = (\n",
    "            frozenset(subset)\n",
    "            for i in range(1, len(itemset))\n",
    "            for subset in combinations(itemset, i)\n",
    "        )\n",
    "        for subset in subsets:\n",
    "            remainder = itemset - subset\n",
    "            if len(remainder) == 0:\n",
    "                continue\n",
    "\n",
    "            # calculate the confidence of the rule subset -> remainder\n",
    "            subset_support = freq_itemsets.get(subset, 0)\n",
    "            confidence = support / subset_support if subset_support > 0 else 0\n",
    "\n",
    "            if abs(confidence) >= min_confidence:\n",
    "                rules.append((subset, remainder, support, confidence))\n",
    "    return rules\n",
    "\n",
    "# Define minimum confidence threshold\n",
    "min_confidence = 0.75\n",
    "\n",
    "# Generate rules from the frequent itemsets\n",
    "association_rules = generate_association_rules(freq_itemsets, min_confidence)\n",
    "df = pd.DataFrame(association_rules, columns=['Antecedent', 'Consequent', 'Support', 'Confidence'])\n",
    "df.sort_values(by='Confidence', ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9033f3-c70a-4f05-9473-5e943f2072d9",
   "metadata": {},
   "source": [
    "The cells below were used to check the algorithm against a library-implemented one, but are no longer necessary. They are included in case confirmation is needed that the algorithm implemented above is indeed correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff2a4d3d-7453-4001-a571-9a97dc539a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f3d40d1-ef7b-402c-8ca5-6f31127f827b",
   "metadata": {},
   "source": [
    "%%time\n",
    "frame3 = apriori(df, min_support=support_threshold / len(dataset), use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d61cc56-f286-4e11-bd1e-38257eac98b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mframe3\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m      2\u001b[0m frame3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m frame3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(x)))\n\u001b[1;32m      3\u001b[0m frame3\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frame3' is not defined"
     ]
    }
   ],
   "source": [
    "frame3['support'] *= len(dataset)\n",
    "frame3['support'] = frame3['support'].apply(lambda x: int(round(x)))\n",
    "frame3.sort_values('support', ascending=False)\n",
    "display(frame3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951f326-b569-4951-9a3a-f3497fe0fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2 = frame3.merge(frame2, how='outer', indicator=True)\n",
    "merged2[merged2['_merge'] != 'both'].sort_values('support')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
